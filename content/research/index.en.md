---
title: "Research"
draft: false

lightgallery: true

math:
  enable: true
---

At SIGNAL group, we have a diverse and continuously expanding scope of research interests spanning the theoretical and algorithm development aspects of  the new generation of AI powered research paradigm that integrates scientific and engineering knowledge into Machine learning and Generative AI. Our team is dedicated to research at the intersection of machine learning, non-parametric statistics, applied probability, and numerical analysis. Our primary focus lies in developing algorithmic and theoretical foundations for modern domains such as `Deep Learning`, `Generative AI`, and `AI4Science`.

![Research](./framework.png)


## Scaling Law of Scientific Machine Learning

How large the sample size and how much computational power are needed to reach a prescribed performance level for a physic problem? In machine learning, a neural scaling law is a scaling law relating parameters of a family of neural networks. We are interested in how physics will affect the scaling law.

<div style="text-align: right;">
<a href="/posts/scalinglaw/">Read more <i class="fas fa-angle-double-right fa-fw"></i></a>
</div>

## Encoding Physics Information into a Model

Our research focus on interpreting many popular neural networks as different numerical discretizations of (stochastic) differential equations. Based on this perspective, we were able to combine physical information with the deep neural network architecture to boost the performance and transparency at the same time.


## Robust Machine Learning

Overparametraization, i.e, having more model parameters than necessary, is the core factor behind the success of modern machine learning. However, overparametraization also enables the model to fit any noisy signal which makes the model extremely vulnerable. Our research aims to build robust overparametrized model via understanding the inductive bias.

