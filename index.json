[{"categories":null,"content":"This article introduce Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space.","date":"2024-05-02","objectID":"/seminars/rkhs/","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"This article introduces Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space. ","date":"2024-05-02","objectID":"/seminars/rkhs/:0:0","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"Reproducing Kernel Banach Space Definition  A reproducing kernel Banach space \\( \\mathcal{B} \\) on a prescribed nonempty set \\( X \\) is a Banach space of certain functions on \\( X \\) such that every point evaluation functional \\( \\delta_x \\), \\( x \\in X \\) on \\( \\mathcal{B} \\) is continuous, that is, there exists a positive constant \\( C_x \\) such that \\[ \\left| \\delta_x(f) \\right| = \\left| f(x) \\right| \\leq C_x | f |_\\mathcal{B} \\text{ for all } f \\in \\mathcal{B}. \\] Note that in all Representer Kernel Banach Space \\( \\mathcal{B} \\) on \\( X \\) norm-convergence implies pointwise convergence, that is, if \\( (f_n) \\subset \\mathcal{B} \\) is a sequence converging to some \\( f \\in \\mathcal{B} \\) in the sense of \\( |f_n - f|_\\mathcal{B} \\rightarrow 0 \\), then \\( f_n(x) \\rightarrow f(x) \\) for all \\( x \\in X \\). ","date":"2024-05-02","objectID":"/seminars/rkhs/:1:0","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"Construction of Reproducing Kernel Banach Space Construction For a Banach space $W$, let $[\\cdot,\\cdot]$ be its duality pairing which is a bi-linear maps from $W\\times W’ \\rightarrow \\mathbb{R}$. Suppose there exist an nonempty set \\( X \\) and a corresponding feature mappings $\\Phi : X \\rightarrow W’,$. We can construct a Reproducing Kernel Banach Space as \\[B := \\{ f_v(x) :=[\\phi(x),v] : v \\in W, x \\in X \\} \\] with norm \\(|{f_v}|_B := \\text{inf} \\{|v|_W: v\\in W\\ \\text{ with }\\ f=[ \\Phi(\\cdot), v ]\\}.\\) ","date":"2024-05-02","objectID":"/seminars/rkhs/:1:1","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"Examples of RKBS Neural Networks Bartolucci, Francesca, et al. “Understanding neural networks with reproducing kernel Banach spaces.” Applied and Computational Harmonic Analysis. Bartolucci, Francesca, et al. “Neural reproducing kernel Banach spaces and representer theorems for deep networks.” arXiv:2403.08750 . \\(L_p\\)-Type RKBS ","date":"2024-05-02","objectID":"/seminars/rkhs/:1:2","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"Representer Theorem Unser, Michael. “A unifying representer theorem for inverse problems and machine learning.” Foundations of Computational Mathematics 2021. ","date":"2024-05-02","objectID":"/seminars/rkhs/:2:0","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"Reproducing Kernel Hilbert Space If a reproducing kernel Hilbert space \\(\\mathcal{H}\\) is a Hilbert space (we have inner product structure), we call it a reproducing kernel Hilbert space. \\(\\left\u003cf,K(x,\\cdot)\\right\u003e=f(x)\\), \\(K(x,y)=\\left\u003cK(x,\\cdot),K(y,\\cdot)\\right\u003e\\). This means \\(K_x:=K(x,\\cdot)\\) is the feature map. Covaraince operator \\(\\Sigma:=\\mathbb{E}_x K_x\\otimes K_x\\) where \\(x\\otimes y=x y^\\top\\) is the operator \\(\\mathcal{H}\\rightarrow\\mathcal{H}\\) defined as \\(g\\otimes h:f\\rightarrow \\left\u003cf,h\\right\u003eg\\). Why we are interested in the Covariance Operator We definte the following operators \\(S:\\mathcal{H}\\rightarrow \\mathcal{L}_2\\) as \\((Sg)(x)=\\left\u003cg,K_x\\right\u003e\\). ","date":"2024-05-02","objectID":"/seminars/rkhs/:3:0","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"Eigendecay and effective rank ","date":"2024-05-02","objectID":"/seminars/rkhs/:3:1","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"Reproducing Kernel Sobolev Space ","date":"2024-05-02","objectID":"/seminars/rkhs/:3:2","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"Characterization of Reproducing Kernel Banach Space using Metric Entropy ","date":"2024-05-02","objectID":"/seminars/rkhs/:4:0","tags":["Statistics","Kernel"],"title":"Reproducing Kernel Hilbert Space and Reproducing Kernel Banach Space","uri":"/seminars/rkhs/"},{"categories":null,"content":"This article shows the basic Markdown syntax and format.","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files. Note This article is a shameful copy of the great Grav original page. If you want to know about the extended Markdown syntax of LoveIt theme, please read extended Markdown syntax page. Let’s face it: Writing content for the Web is tiresome. WYSIWYG editors help alleviate this task, but they generally result in horrible code, or worse yet, ugly web pages. Markdown is a better way to write HTML, without all the complexities and ugliness that usually accompanies it. Some of the key benefits are: Markdown is simple to learn, with minimal extra characters, so it’s also quicker to write content. Less chance of errors when writing in Markdown. Produces valid XHTML output. Keeps the content and the visual display separate, so you cannot mess up the look of your site. Write in any text editor or Markdown application you like. Markdown is a joy to use! John Gruber, the author of Markdown, puts it like this: The overriding design goal for Markdown’s formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it’s been marked up with tags or formatting instructions. While Markdown’s syntax has been influenced by several existing text-to-HTML filters, the single biggest source of inspiration for Markdown’s syntax is the format of plain text email. – John Gruber Without further delay, let us go over the main elements of Markdown and what the resulting HTML looks like! Tip  Bookmark this page for easy future reference! ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:0:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"1 Headings Headings from h2 through h6 are constructed with a # for each level: ## h2 Heading ### h3 Heading #### h4 Heading ##### h5 Heading ###### h6 Heading The HTML looks like this: \u003ch2\u003eh2 Heading\u003c/h2\u003e \u003ch3\u003eh3 Heading\u003c/h3\u003e \u003ch4\u003eh4 Heading\u003c/h4\u003e \u003ch5\u003eh5 Heading\u003c/h5\u003e \u003ch6\u003eh6 Heading\u003c/h6\u003e Heading IDs To add a custom heading ID, enclose the custom ID in curly braces on the same line as the heading: ### A Great Heading {#custom-id} The HTML looks like this: \u003ch3 id=\"custom-id\"\u003eA Great Heading\u003c/h3\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:1:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"2 Comments Comments should be HTML compatible. \u003c!-- This is a comment --\u003e Comment below should NOT be seen: ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:2:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"3 Horizontal Rules The HTML \u003chr\u003e element is for creating a “thematic break” between paragraph-level elements. In Markdown, you can create a \u003chr\u003e with any of the following: ___: three consecutive underscores ---: three consecutive dashes ***: three consecutive asterisks The rendered output looks like this: ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:3:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"4 Body Copy Body copy written as normal, plain text will be wrapped with \u003cp\u003e\u003c/p\u003e tags in the rendered HTML. So this body copy: Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad. The HTML looks like this: \u003cp\u003eLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u003c/p\u003e A line break can be done with one blank line. ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:4:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"5 Inline HTML If you need a certain HTML tag (with a class) you can simply use HTML: Paragraph in Markdown. \u003cdiv class=\"class\"\u003e This is \u003cb\u003eHTML\u003c/b\u003e \u003c/div\u003e Paragraph in Markdown. ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:5:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"6 Emphasis ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:6:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Bold For emphasizing a snippet of text with a heavier font-weight. The following snippet of text is rendered as bold text. **rendered as bold text** __rendered as bold text__ The HTML looks like this: \u003cstrong\u003erendered as bold text\u003c/strong\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:6:1","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Italics For emphasizing a snippet of text with italics. The following snippet of text is rendered as italicized text. *rendered as italicized text* _rendered as italicized text_ The HTML looks like this: \u003cem\u003erendered as italicized text\u003c/em\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:6:2","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Strikethrough In GFMGitHub flavored Markdown you can do strikethroughs. ~~Strike through this text.~~ The rendered output looks like this: Strike through this text. The HTML looks like this: \u003cdel\u003eStrike through this text.\u003c/del\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:6:3","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Combination Bold, italics, and strikethrough can be used in combination. ***bold and italics*** ~~**strikethrough and bold**~~ ~~*strikethrough and italics*~~ ~~***bold, italics and strikethrough***~~ The rendered output looks like this: bold and italics strikethrough and bold strikethrough and italics bold, italics and strikethrough The HTML looks like this: \u003cem\u003e\u003cstrong\u003ebold and italics\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003estrikethrough and bold\u003c/strong\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003estrikethrough and italics\u003c/em\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003ebold, italics and strikethrough\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:6:4","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"7 Blockquotes For quoting blocks of content from another source within your document. Add \u003e before any text you want to quote: \u003e **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. The rendered output looks like this: Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. The HTML looks like this: \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. \u003c/p\u003e \u003c/blockquote\u003e Blockquotes can also be nested: \u003e Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u003e\u003e Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. The rendered output looks like this: Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:7:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"8 Lists ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:8:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Unordered A list of items in which the order of the items does not explicitly matter. You may use any of the following symbols to denote bullets for each list item: * valid bullet - valid bullet + valid bullet For example: * Lorem ipsum dolor sit amet * Consectetur adipiscing elit * Integer molestie lorem at massa * Facilisis in pretium nisl aliquet * Nulla volutpat aliquam velit * Phasellus iaculis neque * Purus sodales ultricies * Vestibulum laoreet porttitor sem * Ac tristique libero volutpat at * Faucibus porta lacus fringilla vel * Aenean sit amet erat nunc * Eget porttitor lorem The rendered output looks like this: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem The HTML looks like this: \u003cul\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit \u003cul\u003e \u003cli\u003ePhasellus iaculis neque\u003c/li\u003e \u003cli\u003ePurus sodales ultricies\u003c/li\u003e \u003cli\u003eVestibulum laoreet porttitor sem\u003c/li\u003e \u003cli\u003eAc tristique libero volutpat at\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ul\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:8:1","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Ordered A list of items in which the order of items does explicitly matter. 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem The rendered output looks like this: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem The HTML looks like this: \u003col\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit\u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ol\u003e Tip If you just use 1. for each number, Markdown will automatically number each item. For example: 1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem The rendered output looks like this: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:8:2","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Task Lists Task lists allow you to create a list of items with checkboxes. To create a task list, add dashes (-) and brackets with a space ([ ]) before task list items. To select a checkbox, add an x in between the brackets ([x]). - [x] Write the press release - [ ] Update the website - [ ] Contact the media The rendered output looks like this: Write the press release Update the website Contact the media ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:8:3","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"9 Code ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:9:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Inline Code Wrap inline snippets of code with `. In this example, `\u003csection\u003e\u003c/section\u003e` should be wrapped as **code**. The rendered output looks like this: In this example, \u003csection\u003e\u003c/section\u003e should be wrapped as code. The HTML looks like this: \u003cp\u003e In this example, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e should be wrapped with \u003cstrong\u003ecode\u003c/strong\u003e. \u003c/p\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:9:1","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Indented Code Or indent several lines of code by at least four spaces, as in: // Some comments line 1 of code line 2 of code line 3 of code The rendered output looks like this: // Some comments line 1 of code line 2 of code line 3 of code The HTML looks like this: \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:9:2","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Block Fenced Code Use “fences” ``` to block in multiple lines of code with a language attribute. ```markdown Sample text here... ``` The HTML looks like this: \u003cpre language-html\u003e \u003ccode\u003eSample text here...\u003c/code\u003e \u003c/pre\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:9:3","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Syntax Highlighting GFMGitHub Flavored Markdown also supports syntax highlighting. To activate it, simply add the file extension of the language you want to use directly after the first code “fence”, ```js, and syntax highlighting will automatically be applied in the rendered HTML. For example, to apply syntax highlighting to JavaScript code: ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ``` The rendered output looks like this: grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; Note Syntax highlighting page in Hugo Docs introduces more about syntax highlighting, including highlight shortcode. ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:9:4","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"10 Tables Tables are created by adding pipes as dividers between each cell, and by adding a line of dashes (also separated by bars) beneath the header. Note that the pipes do not need to be vertically aligned. | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | The rendered output looks like this: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. The HTML looks like this: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e Right or center aligned text Adding a colon on the right side of the dashes below any heading will right align text for that column. Adding colons on both sides of the dashes below any heading will center align text for that column. | Option | Description | |:------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | The rendered output looks like this: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:10:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"11 Links ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:11:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Basic Link \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) The rendered output looks like this (hover over the link, there is no tooltip): https://assemble.io contact@revolunet.com Assemble The HTML looks like this: \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:11:1","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Add a Title [Upstage](https://github.com/upstage/ \"Visit Upstage!\") The rendered output looks like this (hover over the link, there should be a tooltip): Upstage The HTML looks like this: \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:11:2","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"Named Anchors Named anchors enable you to jump to the specified anchor point on the same page. For example, each of these chapters: ## Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3) will jump to these sections: ## Chapter 1 \u003ca id=\"chapter-1\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 2 \u003ca id=\"chapter-2\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 3 \u003ca id=\"chapter-3\"\u003e\u003c/a\u003e Content for chapter one. Note The specific placement of the anchor tag seems to be arbitrary. They are placed inline here since it seems to be unobtrusive, and it works. ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:11:3","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"12 Footnotes Footnotes allow you to add notes and references without cluttering the body of the document. When you create a footnote, a superscript number with a link appears where you added the footnote reference. Readers can click the link to jump to the content of the footnote at the bottom of the page. To create a footnote reference, add a caret and an identifier inside brackets ([^1]). Identifiers can be numbers or words, but they can’t contain spaces or tabs. Identifiers only correlate the footnote reference with the footnote itself — in the output, footnotes are numbered sequentially. Add the footnote using another caret and number inside brackets with a colon and text ([^1]: My footnote.). You don’t have to put footnotes at the end of the document. You can put them anywhere except inside other elements like lists, block quotes, and tables. This is a digital footnote[^1]. This is a footnote with \"label\"[^label] [^1]: This is a digital footnote [^label]: This is a footnote with \"label\" This is a digital footnote1. This is a footnote with “label”2 ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:12:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"13 Images Images have a similar syntax to links but include a preceding exclamation point. ![Minion](https://octodex.github.com/images/minion.png) or: ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The Stormtroopocat Like links, images also have a footnote style syntax: ![Alt text][id] The Dojocat With a reference later in the document defining the URL location: [id]: https://octodex.github.com/images/dojocat.jpg \"The Dojocat\" Tip LoveIt theme has special shortcode for image, which provides more features. This is a digital footnote ↩︎ This is a footnote with “label” ↩︎ ","date":"2022-04-20","objectID":"/seminars/basic-markdown-syntax/:13:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/seminars/basic-markdown-syntax/"},{"categories":null,"content":"This article introduce how to design well-posed machine learning model via Continouous time limit of Machine Learning.","date":"2024-05-21","objectID":"/seminars/continuous/","tags":["Statistics","Dynamic System"],"title":"Well-Posed Machine Learning Model via Continuous Time Limit","uri":"/seminars/continuous/"},{"categories":null,"content":"This article introduce “well-posed” machine learning model via Continouous time limit of Machine Learning. ","date":"2024-05-21","objectID":"/seminars/continuous/:0:0","tags":["Statistics","Dynamic System"],"title":"Well-Posed Machine Learning Model via Continuous Time Limit","uri":"/seminars/continuous/"},{"categories":null,"content":"Well-Posedness ","date":"2024-05-21","objectID":"/seminars/continuous/:1:0","tags":["Statistics","Dynamic System"],"title":"Well-Posed Machine Learning Model via Continuous Time Limit","uri":"/seminars/continuous/"},{"categories":null,"content":"SCALE Lab’s publicatoin in this direction Note SCALE lab is always actively building scaling law for scientific machine learning, here’s the achievement of lab members on this direction Yiping Lu, Haoxuan Chen, Jianfeng Lu, Lexing Ying, Jose Blanchet Machine Learning For Elliptic PDEs: Fast Rate Generalization Bound, Neural Scaling Law and Minimax Optimality, Tenth International Conference on Learning Representations(ICLR) 2022 Yiping Lu, Jose Blanchet,Lexing Ying Sobolev Acceleration and Statistical Optimality for Learning Elliptic Equations via Gradient Descent, Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS) 2022 Jikai Jin, Yiping Lu, Jose Blanchet, Lexing Ying Minimax Optimal Kernel Operator Learning via Multilevel Training, Eleventh International Conference on Learning Representations(ICLR) 2023 Honam Wong, Wendao Wu, Fanghui Liu, Yiping Lu Physics-Informed Learning Interpolates Well in Fixed Dimension: Inductive Bias and Benign Overfitting, Submitted ","date":"2022-05-12","objectID":"/posts/scalinglaw/:1:0","tags":["Scientific Machine Learning"],"title":"Scaling Law of Scientific Machine Learning","uri":"/posts/scalinglaw/"},{"categories":null,"content":"Scaling Law The term “scaling laws” in deep learning refers to relations between functional properties of interest (usually the test loss or some performance metric for fine-tuning tasks) and properties of the architecture or optimization process (like model size, width, or training compute). These laws can help inform the design and training of deep learning models, as well as provide insights into their underlying principles. ","date":"2022-05-12","objectID":"/posts/scalinglaw/:2:0","tags":["Scientific Machine Learning"],"title":"Scaling Law of Scientific Machine Learning","uri":"/posts/scalinglaw/"},{"categories":null,"content":"Statistical Model For Physics Informed Machine Learning ","date":"2022-05-12","objectID":"/posts/scalinglaw/:3:0","tags":["Scientific Machine Learning"],"title":"Scaling Law of Scientific Machine Learning","uri":"/posts/scalinglaw/"},{"categories":null,"content":"Physics-Informed Machine Learning Physics-Informed Machine Learning (PIML) aims to solve equation \\(\\mathcal{A}u=f\\) using observations of function \\(f\\). ","date":"2022-05-12","objectID":"/posts/scalinglaw/:3:1","tags":["Scientific Machine Learning"],"title":"Scaling Law of Scientific Machine Learning","uri":"/posts/scalinglaw/"},{"categories":null,"content":"Operator Learning ","date":"2022-05-12","objectID":"/posts/scalinglaw/:3:2","tags":["Scientific Machine Learning"],"title":"Scaling Law of Scientific Machine Learning","uri":"/posts/scalinglaw/"},{"categories":null,"content":"Inductive Bias We also considered the following two estimators Regularized Least Square \\(\\text{argmin}u |\\mathcal{A}(u)-f|^2+|f|\\beta^2\\) Minimum Norm Interpolation \\(\\text{argmin}u | |f|\\beta^2\\) subject to \\((\\mathcal{A}u)(x_i)=f(x_i)\\) ","date":"2022-05-12","objectID":"/posts/scalinglaw/:4:0","tags":["Scientific Machine Learning"],"title":"Scaling Law of Scientific Machine Learning","uri":"/posts/scalinglaw/"},{"categories":null,"content":"TO DO ","date":"2022-05-12","objectID":"/posts/scasml/:0:0","tags":["Scientific Machine Learning"],"title":"Simulation Calibrated Scientific Machine Learning","uri":"/posts/scasml/"},{"categories":null,"content":"欢迎来到重庆大学网络安全实验室 我们是重庆大学计算机学院一个充满活力的研究小组。我们的目标是在21世纪计算机技术飞速发展的背景下，探索和解决人工智能和计算机领域潜在的安全问题。我们团队希望在保障安全与隐私信息的同时，积极探索大数据时代发展的新方向，尝试解决机器学习浪潮下面临的安全问题，希望能够提出新的理论，推动计算机领域的发展，将成熟的技术应用到生活的各个领域，进而推动社会的发展和进步。 新闻 查看更多  快速访问 ","date":"0001-01-01","objectID":"/_index.zh-cn/:0:0","tags":null,"title":"","uri":"/_index.zh-cn/"},{"categories":null,"content":"Location 2145 Sheridan Rd, Evanston, IL 60208 ","date":"0001-01-01","objectID":"/contact/:1:0","tags":null,"title":"Contact","uri":"/contact/"},{"categories":null,"content":"2024 🎉 Yiping will serve as an Area Chiar (AC) for Neurips 2024!    2024-04 Yiping will serve as an Area Chiar (AC) for Neurips 2024! 📚 Yiping is going to give a tutorial at AAAI 2024 on Recent Advance in Physics-Informed Machine Learning!    2024-02 Here is the link to the homepage of the tutorial. Here is the slide. 🎉 Congrats Yiping to his recent CPAL Rising Star award!    2024-01 Yiping is among the first cohert of the CPAL Rising Stars Awardees. ","date":"0001-01-01","objectID":"/news/:1:0","tags":null,"title":"News","uri":"/news/"},{"categories":null,"content":"Preprint a paper on kernel solver for inverse problem Honam Wong, Wendao Wu, Fanghui Liu and Yiping Lu submitted. a paper on reproducing kernel banach space Yiping Lu, Daozhe Lin and Qiang Du submitted. ","date":"0001-01-01","objectID":"/publications/:1:0","tags":null,"title":"Publications","uri":"/publications/"},{"categories":null,"content":"2024 Orthogonal Bootstrap: Efficient Simulation of Input Uncertainty Kaizhao Liu, Jose Blanchet, Lexing Ying and Yiping Lu The Forty-first International Conference on Machine Learning (ICML 2024). Synthetic Principal Component Design: Fast Covariate Balancing with Synthetic Controls (Oral) Yiping Lu, Jiajin Li, Lexing Ying and Jose Blanchet 40th Conference on Uncertainty in Artificial Intelligence (UAI 2024) Generalization Guarantees of Deep ResNets in the Mean-Field Regime (Spotlight) Yihang Chen, Fanghui Liu, Yiping Lu, Grigorios Chrysos and Volkan Cevher International Conference on Learning Representations(ICLR) 2024 Statistical Spatially Inhomogeneous Diffusion Inference Yinuo Ren, Yiping Lu, Lexing Ying and Grant Rotskoff The 38th Annual AAAI Conference on Artificial Intelligence, 2024 ","date":"0001-01-01","objectID":"/publications/:2:0","tags":null,"title":"Publications","uri":"/publications/"},{"categories":null,"content":"Early Years When can Regression-Adjusted Control Variates Help? Rare Events, Sobolev Embedding and Minimax Optimality Jose Blanchet, Haoxuan Chen, Yiping Lu and Lexing Ying Thirty-seventh Conference on Neural Information Processing Systems (Neurips) 2023 Minimax Optimal Kernel Operator Learning via Multilevel Training (Spotlight) Jikai Jin, Yiping Lu, Jose Blanchet, Lexing Ying Eleventh International Conference on Learning Representations(ICLR) 2023 Adversarial Noises Are Linearly Separable for (Nearly) Random Neural Networks Huishuai Zhang, Da yu, Yiping Lu and Di He 26th International Conference on Artificial Intelligence and Statistics (AISTATS) 2023 Sobolev Acceleration and Statistical Optimality for Learning Elliptic Equations via Gradient Descent Yiping Lu, Jose Blanchet,Lexing Ying Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS) 2022 Machine Learning For Elliptic PDEs: Fast Rate Generalization Bound, Neural Scaling Law and Minimax Optimality (Spotlight Talk at NeurIPS 2021 Workshop on Integration of Deep Learning and Differential Equation) Yiping Lu, Haoxuan Chen, Jianfeng Lu, Lexing Ying, Jose Blanchet 10th International Conference on Learning Representations(ICLR) 2022 An Unconstrained Layer-Peeled Perspective on Neural Collapse Wenlong Ji, Yiping Lu, Yiliang Zhang, Zhun Deng, Weijie J Su Tenth International Conference on Learning Representations(ICLR) 2022 CURE: Curvature Regularization For Missing Data Recovery Bin Dong, Haochen Ju, Yiping Lu, Zuoqiang Shi SIAM Journal on Imaging Science, 13(4), 2169-2188, 2020 A Mean-field Analysis of Deep ResNet and Beyond: Towards Provable Optimization Via Overparameterization From Depth (Contributed Talk at ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations.) Yiping Lu, Chao Ma, Yulong Lu, Jianfeng Lu, Lexing Ying Thirty-seventh International Conference on Machine Learning (ICML), 2020 Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View Yiping Lu *, Zhuohan Li*, Di He, Zhiqing Sun, Bin Dong, Tao Qin, Liwei Wang, Tie-yan Liu You Only Propagate Once: Painless Adversarial Training Using Maximal Principle Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, Bin Dong 33rd Annual Conference on Neural Information Processing Systems (NeurIPS) 2019 PDE-Net 2.0: Learning PDEs from Data with A Numeric-Symbolic Hybrid Deep Network Zichao Long, Yiping Lu, Bin Dong Journal of Computational Physics Dynamically Unfolding Recurrent Restorer: A Moving Endpoint Control Method for Image Restoration Xiaoshuai Zhang*, Yiping Lu , Jiaying Liu, Bin Dong. Seventh International Conference on Learning Representations(ICLR) 2019 PDE-Net:Learning PDEs From Data Zichao long*, Yiping Lu *, Xianzhong Ma*, Bin Dong Thirty-fifth International Conference on Machine Learning (ICML), 2018 Beyond Finite Layer Neural Network:Bridging Deep Architects and Numerical Differential Equations Yiping Lu, Aoxiao Zhong, Quanzheng Li, Bin Dong. Thirty-fifth International Conference on Machine Learning (ICML), 2018 ","date":"0001-01-01","objectID":"/publications/:3:0","tags":null,"title":"Publications","uri":"/publications/"},{"categories":null,"content":"At SCALE group, we have a diverse and continuously expanding scope of research interests spanning the theoretical and algorithm development aspects of the new generation of AI powered research paradigm that integrates scientific and engineering knowledge into Machine learning and Generative AI. Our team is dedicated to research at the intersection of machine learning, non-parametric statistics, applied probability, and numerical analysis. Our primary focus lies in developing algorithmic and theoretical foundations for modern domains such as Deep Learning, Generative AI, and AI4Science. Potential Topics: Large Foundation Models for Science, Computational Complexity for Scientific Computing, Banach Space Geometry, Simulation Free (Diffusion) Models for Science, Trustworthy Machine Learning and Calibration ","date":"0001-01-01","objectID":"/research/:0:0","tags":null,"title":"Research","uri":"/research/"},{"categories":null,"content":"Scaling Law of Scientific Machine Learning How large the sample size and how much computational power are needed to reach a prescribed performance level for a physic problem? In machine learning, a neural scaling law (one of the secrete makes language model works) is a scaling law relating parameters of a family of neural networks. We are interested in how physics will affect the scaling law. Read more ","date":"0001-01-01","objectID":"/research/:1:0","tags":null,"title":"Research","uri":"/research/"},{"categories":null,"content":"Foundation of Machine Learning Machine learning has achieved great success in many applications such as image recognition and language models. However, the reason why machine learning is so powerful remains elusive. One of the secrete behind this is machine learning provides powerful function/functional approximator in high dimension. Our group aims to understand the mysterious of machine learning using functional analysis, high-dimensional statistics and high-dimensional probability. ","date":"0001-01-01","objectID":"/research/:2:0","tags":null,"title":"Research","uri":"/research/"},{"categories":null,"content":"Encoding Physics Information into a Model Our research focus on interpreting many popular neural networks as different numerical discretizations of (stochastic) differential equations. Based on this perspective, we were able to combine physical information with the deep neural network architecture to boost the performance and transparency at the same time. ","date":"0001-01-01","objectID":"/research/:3:0","tags":null,"title":"Research","uri":"/research/"},{"categories":null,"content":"Robust Machine Learning Overparametraization, i.e, having more model parameters than necessary, is the core factor behind the success of modern machine learning. However, overparametraization also enables the model to fit any noisy signal which makes the model extremely vulnerable. Our research aims to build robust overparametrized model via understanding the inductive bias. ","date":"0001-01-01","objectID":"/research/:4:0","tags":null,"title":"Research","uri":"/research/"},{"categories":null,"content":"Course Offered by SCALE LAB ","date":"0001-01-01","objectID":"/teaching/:0:0","tags":null,"title":"Teaching","uri":"/teaching/"},{"categories":null,"content":"IEMS-304 Statistical Learning for Data Analysis Predictive modeling of data using modern regression and classification methods. Multiple linear regression; logistic regression; pitfalls and diagnostics; nonparametric and nonlinear regression and classification such as trees, nearest neighbors, neural networks, and ensemble methods. Read more ","date":"0001-01-01","objectID":"/teaching/:1:0","tags":null,"title":"Teaching","uri":"/teaching/"},{"categories":null,"content":"IEMS 402 - Statistical Learning Required graduate course on mathematical foundations of data science. Read more ","date":"0001-01-01","objectID":"/teaching/:2:0","tags":null,"title":"Teaching","uri":"/teaching/"},{"categories":null,"content":"Principal Investigator Yiping Lu  Assistant Professor  yiping [dot] lu [at] northwestern [dot] edu  Yiping is a tenure-track assistant professor at Industrial Engineering \u0026 Management Science, Northwestern University. Prior to that, he worked as a Courant instructor for one year at Courant Institute of Mathematical Sciences. He received his Ph.D. degree in applied math from Stanford University in 2023 and my Bachelor’s degree in applied math from Peking University in 2019. Yiping was a recipient of the Conference on Parsimony and Learning (CPAL) Rising Star Award in 2024, the Rising Star in Data Science from the University of Chicago in 2022. He also serves as an area chair for flagship machine learning conferences such as NeurIPS and AISTATS. ","date":"0001-01-01","objectID":"/team/:1:0","tags":null,"title":"Team","uri":"/team/"},{"categories":null,"content":"Student ","date":"0001-01-01","objectID":"/team/:2:0","tags":null,"title":"Team","uri":"/team/"},{"categories":null,"content":"Ph.D. Name Interests ","date":"0001-01-01","objectID":"/team/:2:1","tags":null,"title":"Team","uri":"/team/"},{"categories":null,"content":"Visiting Students Name Interests Chenguang Duan non-parametric statistics, stochastic control (WHU) ","date":"0001-01-01","objectID":"/team/:2:2","tags":null,"title":"Team","uri":"/team/"},{"categories":null,"content":"Master and Undergrads Name Interests Achievement Kaizhao Liu (2025) Machine Learning Theory (PKU) First Author paper in ICML 2024 Siyuan Tang (2025) Direct Preference Optimization (co-supervised with Minshuo Chen) (USTC) Honam Wong (2025) Machine Learning Theory (HKUST) First Author paper submitted to Neurips 2024 Ruihan Xu (2025) Machine Learning Theory, Applied Math (SJTU) Wendao Wu (2026) Machine Learning Theory, Applied Math (PKU) Second Author paper submitted to Neurips 2024 Zexi Fan (2027) Scientific Machine Learning, Stochasatic Control (PKU) ","date":"0001-01-01","objectID":"/team/:2:3","tags":null,"title":"Team","uri":"/team/"},{"categories":null,"content":"Alumni Name Next Position Achievement Wenlong Ji Stanford Statistics Ph.D First Author paper in ICLR 2022 Haoxuan Chen Stanford ICME Ph.D First Author paper in ICLR 2022 Jikai Jin Stanford ICME Ph.D First Author paper in ICLR 2023 (spotlight) ","date":"0001-01-01","objectID":"/team/:2:4","tags":null,"title":"Team","uri":"/team/"}]